{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Demo: Keywords Enhance Document Retrieval\n",
    "\n",
    "**Core Concept:** YAKE keywords stored as metadata improve RAG retrieval\n",
    "\n",
    "1. Extract keywords from documents using YAKE\n",
    "2. Store keywords as metadata in ChromaDB\n",
    "3. Show keyword overlap to explain why documents are retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from yake import KeywordExtractor\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import chromadb\n",
    "\n",
    "load_dotenv()\n",
    "DOCS_DIR = Path(\"demo_documents\")\n",
    "DB_DIR = \"./chroma_db\"\n",
    "\n",
    "def extract_keywords(text: str, top: int = 15):\n",
    "    extractor = KeywordExtractor(n=2, top=top, dedup_threshold=0.6)\n",
    "    return [kw for kw, score in extractor.extract_keywords(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Index Documents with Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ auth_guide.txt\n",
      "  Keywords: Authentication Guide, Guide, Client Credentials, Flow Deprecated, Implicit Flow...\n",
      "\n",
      "✓ ml_guide.txt\n",
      "  Keywords: Learning Guide, Guide, Concepts Supervised, Neural Networks, Forests Ensemble...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup ChromaDB\n",
    "client = chromadb.PersistentClient(path=DB_DIR)\n",
    "try:\n",
    "    client.delete_collection(\"demo\")\n",
    "except:\n",
    "    pass\n",
    "collection = client.create_collection(\"demo\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Index documents\n",
    "for txt_file in DOCS_DIR.glob(\"*.txt\"):\n",
    "    text = txt_file.read_text()\n",
    "    keywords = extract_keywords(text, top=15)\n",
    "    embedding = embeddings.embed_query(text)\n",
    "    \n",
    "    collection.add(\n",
    "        ids=[txt_file.stem],\n",
    "        embeddings=[embedding],\n",
    "        documents=[text],\n",
    "        metadatas=[{\"keywords\": \", \".join(keywords), \"filename\": txt_file.name}]\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ {txt_file.name}\")\n",
    "    print(f\"  Keywords: {', '.join(keywords[:5])}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Search with Keyword Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_keywords(query: str):\n",
    "    # Extract keywords from query\n",
    "    query_keywords = extract_keywords(query, top=5)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Keywords: {', '.join(query_keywords)}\\n\")\n",
    "    \n",
    "    # Search\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=2)\n",
    "    \n",
    "    # Show results\n",
    "    for i, metadata in enumerate(results['metadatas'][0], 1):\n",
    "        doc_keywords = metadata['keywords'].split(', ')\n",
    "        \n",
    "        # Find keyword overlap (case-insensitive)\n",
    "        query_kw_lower = [kw.lower() for kw in query_keywords]\n",
    "        doc_kw_lower = [kw.lower() for kw in doc_keywords]\n",
    "        \n",
    "        overlap = []\n",
    "        for qkw in query_kw_lower:\n",
    "            for dkw in doc_kw_lower:\n",
    "                if qkw in dkw or dkw in qkw:\n",
    "                    overlap.append(f\"{qkw}↔{dkw}\")\n",
    "        \n",
    "        print(f\"{i}. {metadata['filename']}\")\n",
    "        if overlap:\n",
    "            print(f\"Overlap: {', '.join(overlap[:3])}\")\n",
    "        else:\n",
    "            print(f\"No overlap\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Different Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about OAuth and authentication methods\n",
      "Keywords: authentication methods, OAuth, methods\n",
      "\n",
      "1. auth_guide.txt\n",
      "   ✓ Overlap: oauth↔oauth industry\n",
      "2. ml_guide.txt\n",
      "   ✗ No overlap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_with_keywords(\"Tell me about OAuth and authentication methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is machine learning and neural networks\n",
      "Keywords: machine learning, neural networks, learning, machine\n",
      "\n",
      "1. ml_guide.txt\n",
      "   ✓ Overlap: machine learning↔machine, neural networks↔neural networks, neural networks↔neural\n",
      "2. auth_guide.txt\n",
      "   ✗ No overlap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_with_keywords(\"What is machine learning and neural networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: RAG Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the OAuth 2.0 flows for authentication?\n",
      "\n",
      "Answer: The OAuth 2.0 flows for authentication include:\n",
      "\n",
      "1. **Authorization Code Flow**: This is the most secure method for web applications, where an authorization code is exchanged for an access token after the user authenticates.\n",
      "\n",
      "2. **Client Credentials Flow**: This flow is used for machine-to-machine authentication, where the client application authenticates itself to obtain an access token without user interaction.\n",
      "\n",
      "3. **Implicit Flow**: This flow has been deprecated for security reasons and is no longer recommended for use. \n",
      "\n",
      "These flows are designed to facilitate secure authorization in various application scenarios.\n",
      "\n",
      "Source: auth_guide.txt\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "question = \"What are the OAuth 2.0 flows for authentication?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "# Retrieve and answer\n",
    "query_embedding = embeddings.embed_query(question)\n",
    "results = collection.query(query_embeddings=[query_embedding], n_results=1)\n",
    "context = results['documents'][0][0]\n",
    "source = results['metadatas'][0][0]['filename']\n",
    "\n",
    "prompt = f\"Based on this context, answer the question.\\n\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "answer = llm.invoke(prompt).content\n",
    "\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"\\nSource: {source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "**Keywords as metadata provide:**\n",
    "\n",
    "Better precision (filter by specific terms)  \n",
    "Explainability (see keyword overlap)  \n",
    "Domain knowledge (capture technical terms)\n",
    "\n",
    "**This system's YAKE extractor becomes the metadata engine for RAG!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Your Own Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify and run\n",
    "search_with_keywords(\"Your question here\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-text-tagger-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
