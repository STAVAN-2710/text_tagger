{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Demo: Keywords Enhance Document Retrieval\n",
    "\n",
    "**Core Concept:** YAKE keywords stored as metadata improve RAG retrieval\n",
    "\n",
    "1. Extract keywords from documents using YAKE\n",
    "2. Store keywords as metadata in ChromaDB\n",
    "3. Show keyword overlap to explain why documents are retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from yake import KeywordExtractor\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import chromadb\n",
    "\n",
    "load_dotenv()\n",
    "DOCS_DIR = Path(\"demo_documents\")\n",
    "DB_DIR = \"./chroma_db\"\n",
    "\n",
    "def extract_keywords(text: str, top: int = 15):\n",
    "    extractor = KeywordExtractor(n=2, top=top, dedup_threshold=0.6)\n",
    "    return [kw for kw, score in extractor.extract_keywords(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Index Documents with Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ChromaDB\n",
    "client = chromadb.PersistentClient(path=DB_DIR)\n",
    "try:\n",
    "    client.delete_collection(\"demo\")\n",
    "except:\n",
    "    pass\n",
    "collection = client.create_collection(\"demo\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Index documents\n",
    "for txt_file in DOCS_DIR.glob(\"*.txt\"):\n",
    "    text = txt_file.read_text()\n",
    "    keywords = extract_keywords(text, top=15)\n",
    "    embedding = embeddings.embed_query(text)\n",
    "    \n",
    "    collection.add(\n",
    "        ids=[txt_file.stem],\n",
    "        embeddings=[embedding],\n",
    "        documents=[text],\n",
    "        metadatas=[{\"keywords\": \", \".join(keywords), \"filename\": txt_file.name}]\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ {txt_file.name}\")\n",
    "    print(f\"  Keywords: {', '.join(keywords[:5])}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Search with Keyword Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_keywords(query: str):\n",
    "    # Extract keywords from query\n",
    "    query_keywords = extract_keywords(query, top=5)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Keywords: {', '.join(query_keywords)}\\n\")\n",
    "    \n",
    "    # Search\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=2)\n",
    "    \n",
    "    # Show results\n",
    "    for i, metadata in enumerate(results['metadatas'][0], 1):\n",
    "        doc_keywords = metadata['keywords'].split(', ')\n",
    "        \n",
    "        # Find keyword overlap (case-insensitive)\n",
    "        query_kw_lower = [kw.lower() for kw in query_keywords]\n",
    "        doc_kw_lower = [kw.lower() for kw in doc_keywords]\n",
    "        \n",
    "        overlap = []\n",
    "        for qkw in query_kw_lower:\n",
    "            for dkw in doc_kw_lower:\n",
    "                if qkw in dkw or dkw in qkw:\n",
    "                    overlap.append(f\"{qkw}↔{dkw}\")\n",
    "        \n",
    "        print(f\"{i}. {metadata['filename']}\")\n",
    "        if overlap:\n",
    "            print(f\"   ✓ Overlap: {', '.join(overlap[:3])}\")\n",
    "        else:\n",
    "            print(f\"   ✗ No overlap\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Different Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_keywords(\"Tell me about OAuth and authentication methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_with_keywords(\"What is machine learning and neural networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: RAG Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "question = \"What are the OAuth 2.0 flows for authentication?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "# Retrieve and answer\n",
    "query_embedding = embeddings.embed_query(question)\n",
    "results = collection.query(query_embeddings=[query_embedding], n_results=1)\n",
    "context = results['documents'][0][0]\n",
    "source = results['metadatas'][0][0]['filename']\n",
    "\n",
    "prompt = f\"Based on this context, answer the question.\\n\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "answer = llm.invoke(prompt).content\n",
    "\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"\\nSource: {source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "**Keywords as metadata provide:**\n",
    "\n",
    "✅ Better precision (filter by specific terms)  \n",
    "✅ Explainability (see keyword overlap)  \n",
    "✅ Domain knowledge (capture technical terms)\n",
    "\n",
    "**This system's YAKE extractor becomes the metadata engine for RAG!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Your Own Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify and run\n",
    "search_with_keywords(\"Your question here\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
